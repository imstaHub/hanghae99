{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week5 Advanced Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-community langchain-openai langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "#from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "#from langchain.document_loaders import UnstructuredFileLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [MY CODE] 논문 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "논문 페이지 수: 19\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(\n",
    "    file_path= 'RAG_paper.pdf',\n",
    ")\n",
    "docs = loader.load()\n",
    "print('논문 페이지 수:', len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'RAG_paper.pdf', 'page': 0}, page_content='Retrieval-Augmented Generation for\\nKnowledge-Intensive NLP Tasks\\nPatrick Lewis†‡, Ethan Perez⋆,\\nAleksandra Piktus†, Fabio Petroni†, Vladimir Karpukhin†, Naman Goyal†, Heinrich Küttler†,\\nMike Lewis†, Wen-tau Yih†, Tim Rocktäschel†‡, Sebastian Riedel†‡, Douwe Kiela†\\n†Facebook AI Research; ‡University College London; ⋆New York University;\\nplewis@fb.com\\nAbstract\\nLarge pre-trained language models have been shown to store factual knowledge\\nin their parameters, and achieve state-of-the-art results when ﬁne-tuned on down-\\nstream NLP tasks. However, their ability to access and precisely manipulate knowl-\\nedge is still limited, and hence on knowledge-intensive tasks, their performance\\nlags behind task-speciﬁc architectures. Additionally, providing provenance for their\\ndecisions and updating their world knowledge remain open research problems. Pre-\\ntrained models with a differentiable access mechanism to explicit non-parametric\\nmemory have so far been only investigated for extractive downstream tasks. We\\nexplore a general-purpose ﬁne-tuning recipe for retrieval-augmented generation\\n(RAG) — models which combine pre-trained parametric and non-parametric mem-\\nory for language generation. We introduce RAG models where the parametric\\nmemory is a pre-trained seq2seq model and the non-parametric memory is a dense\\nvector index of Wikipedia, accessed with a pre-trained neural retriever. We com-\\npare two RAG formulations, one which conditions on the same retrieved passages\\nacross the whole generated sequence, and another which can use different passages\\nper token. We ﬁne-tune and evaluate our models on a wide range of knowledge-\\nintensive NLP tasks and set the state of the art on three open domain QA tasks,\\noutperforming parametric seq2seq models and task-speciﬁc retrieve-and-extract\\narchitectures. For language generation tasks, we ﬁnd that RAG models generate\\nmore speciﬁc, diverse and factual language than a state-of-the-art parametric-only\\nseq2seq baseline.\\n1 Introduction\\nPre-trained neural language models have been shown to learn a substantial amount of in-depth knowl-\\nedge from data [47]. They can do so without any access to an external memory, as a parameterized\\nimplicit knowledge base [51, 52]. While this development is exciting, such models do have down-\\nsides: They cannot easily expand or revise their memory, can’t straightforwardly provide insight into\\ntheir predictions, and may produce “hallucinations” [38]. Hybrid models that combine parametric\\nmemory with non-parametric (i.e., retrieval-based) memories [20, 26, 48] can address some of these\\nissues because knowledge can be directly revised and expanded, and accessed knowledge can be\\ninspected and interpreted. REALM [ 20] and ORQA [ 31], two recently introduced models that\\ncombine masked language models [8] with a differentiable retriever, have shown promising results,\\narXiv:2005.11401v4  [cs.CL]  12 Apr 2021')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할 수: 19\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",  \n",
    "    chunk_size=3000, \n",
    "    chunk_overlap=500,\n",
    ")\n",
    "\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "print('분할 수:', len(split_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'RAG_paper.pdf', 'page': 0}, page_content='Retrieval-Augmented Generation for\\nKnowledge-Intensive NLP Tasks\\nPatrick Lewis†‡, Ethan Perez⋆,\\nAleksandra Piktus†, Fabio Petroni†, Vladimir Karpukhin†, Naman Goyal†, Heinrich Küttler†,\\nMike Lewis†, Wen-tau Yih†, Tim Rocktäschel†‡, Sebastian Riedel†‡, Douwe Kiela†\\n†Facebook AI Research; ‡University College London; ⋆New York University;\\nplewis@fb.com\\nAbstract\\nLarge pre-trained language models have been shown to store factual knowledge\\nin their parameters, and achieve state-of-the-art results when ﬁne-tuned on down-\\nstream NLP tasks. However, their ability to access and precisely manipulate knowl-\\nedge is still limited, and hence on knowledge-intensive tasks, their performance\\nlags behind task-speciﬁc architectures. Additionally, providing provenance for their\\ndecisions and updating their world knowledge remain open research problems. Pre-\\ntrained models with a differentiable access mechanism to explicit non-parametric\\nmemory have so far been only investigated for extractive downstream tasks. We\\nexplore a general-purpose ﬁne-tuning recipe for retrieval-augmented generation\\n(RAG) — models which combine pre-trained parametric and non-parametric mem-\\nory for language generation. We introduce RAG models where the parametric\\nmemory is a pre-trained seq2seq model and the non-parametric memory is a dense\\nvector index of Wikipedia, accessed with a pre-trained neural retriever. We com-\\npare two RAG formulations, one which conditions on the same retrieved passages\\nacross the whole generated sequence, and another which can use different passages\\nper token. We ﬁne-tune and evaluate our models on a wide range of knowledge-\\nintensive NLP tasks and set the state of the art on three open domain QA tasks,\\noutperforming parametric seq2seq models and task-speciﬁc retrieve-and-extract\\narchitectures. For language generation tasks, we ﬁnd that RAG models generate\\nmore speciﬁc, diverse and factual language than a state-of-the-art parametric-only\\nseq2seq baseline.\\n1 Introduction\\nPre-trained neural language models have been shown to learn a substantial amount of in-depth knowl-\\nedge from data [47]. They can do so without any access to an external memory, as a parameterized\\nimplicit knowledge base [51, 52]. While this development is exciting, such models do have down-\\nsides: They cannot easily expand or revise their memory, can’t straightforwardly provide insight into\\ntheir predictions, and may produce “hallucinations” [38]. Hybrid models that combine parametric\\nmemory with non-parametric (i.e., retrieval-based) memories [20, 26, 48] can address some of these\\nissues because knowledge can be directly revised and expanded, and accessed knowledge can be\\ninspected and interpreted. REALM [ 20] and ORQA [ 31], two recently introduced models that\\ncombine masked language models [8] with a differentiable retriever, have shown promising results,\\narXiv:2005.11401v4  [cs.CL]  12 Apr 2021')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [LOG] page별로 문서를 로드하고 split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [MY CODE] MapReduce로 논문 요약 구현 (old version - LLMChain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gj/86sxmqd95yd0hskfrsflrx480000gp/T/ipykernel_95985/4193787190.py:18: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  map_chain = LLMChain(llm=llm, prompt=map_prompt)\n"
     ]
    }
   ],
   "source": [
    "# Map에 사용할 prompt template\n",
    "map_template = \"\"\"다음은 문서 중 일부 내용입니다\n",
    "{pages}\n",
    "이 문서 목록을 기반으로 주요 내용을 요약해 주세요.\n",
    "답변: \"\"\"\n",
    "\n",
    "# Map 프롬프트\n",
    "map_prompt = PromptTemplate.from_template(map_template)\n",
    "\n",
    "# Map에서 수행할 LLMChain 정의\n",
    "llm = ChatOpenAI(temperature=0, \n",
    "                 model_name='gpt-4o-mini',\n",
    "                 api_key=api_key)\n",
    "map_chain = LLMChain(llm=llm, prompt=map_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce에 사용할 prompt template\n",
    "reduce_template = \"\"\"다음은 요약의 집합입니다:\n",
    "{doc_summaries}\n",
    "이것으로 통합된 요약을 만들어 주세요.\n",
    "답변: \"\"\"\n",
    "\n",
    "# Reduce 프롬프트\n",
    "reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
    "\n",
    "# Reduce에서 수행할 LLMChain 정의\n",
    "reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gj/86sxmqd95yd0hskfrsflrx480000gp/T/ipykernel_95985/4154098370.py:5: LangChainDeprecationWarning: This class is deprecated. Use the `create_stuff_documents_chain` constructor instead. See migration guide here: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain/\n",
      "  combine_documents_chain = StuffDocumentsChain(\n",
      "/var/folders/gj/86sxmqd95yd0hskfrsflrx480000gp/T/ipykernel_95985/4154098370.py:11: LangChainDeprecationWarning: This class is deprecated. Please see the migration guide here for a recommended replacement: https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain/\n",
      "  reduce_documents_chain = ReduceDocumentsChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains import ReduceDocumentsChain\n",
    "\n",
    "# 문서의 목록을 받아들여, 이를 단일 문자열로 결합하고, 이를 LLMChain에 전달\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain,                \n",
    "    document_variable_name=\"doc_summaries\"\n",
    ")\n",
    "\n",
    "# Map 문서를 통합하고 순차적으로 Reduce합니다.\n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    combine_documents_chain=combine_documents_chain,    # 호출되는 최종 체인입니다.\n",
    "    collapse_documents_chain=combine_documents_chain,   # 문서가 `StuffDocumentsChain`의 컨텍스트를 초과하는 경우\n",
    "    token_max=4000,                                     # 문서를 그룹화할 때의 토큰 최대 개수입니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gj/86sxmqd95yd0hskfrsflrx480000gp/T/ipykernel_95985/2103415951.py:4: LangChainDeprecationWarning: This class is deprecated. Please see the migration guide here for a recommended replacement: https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain/\n",
      "  map_reduce_chain = MapReduceDocumentsChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import MapReduceDocumentsChain\n",
    "\n",
    "# 문서들에 체인을 매핑하여 결합하고, 그 다음 결과들을 결합합니다.\n",
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    llm_chain=map_chain,\n",
    "    reduce_documents_chain=reduce_documents_chain,\n",
    "    document_variable_name=\"pages\",\n",
    "    return_intermediate_steps=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gj/86sxmqd95yd0hskfrsflrx480000gp/T/ipykernel_95985/3595548341.py:3: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = map_reduce_chain.run(split_docs)\n"
     ]
    }
   ],
   "source": [
    "# Map-Reduce chain\n",
    "result = map_reduce_chain.run(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 문서는 Retrieval-Augmented Generation (RAG) 모델에 대한 포괄적인 연구를 다루고 있으며, 이 모델은 사전 훈련된 검색기와 시퀀스-투-시퀀스(seq2seq) 생성 모델을 결합하여 지식 집약적인 자연어 처리(NLP) 작업을 수행하는 데 중점을 두고 있습니다. 주요 내용은 다음과 같습니다:\n",
      "\n",
      "1. **모델 구조 및 하이브리드 메모리**: RAG 모델은 입력 쿼리에 대해 관련 문서를 검색하는 검색기와 검색된 문서를 기반으로 텍스트를 생성하는 생성기로 구성됩니다. 이 모델은 파라메트릭 메모리(사전 훈련된 seq2seq 모델)와 비파라메트릭 메모리(밀집 벡터 인덱스)를 결합하여 외부 지식 소스에 접근할 수 있도록 합니다.\n",
      "\n",
      "2. **성능 평가**: RAG 모델은 Natural Questions, WebQuestions, CuratedTrec와 같은 데이터셋에서 최첨단 성능을 달성하였으며, Jeopardy 질문 생성 및 FEVER 사실 검증 작업에서도 우수한 결과를 보였습니다. RAG는 BART 모델과 비교하여 더 사실적이고 구체적인 응답을 생성하는 경향이 있습니다.\n",
      "\n",
      "3. **디코딩 방법**: RAG 모델은 RAG-Sequence와 RAG-Token 두 가지 방식으로 디코딩을 수행합니다. RAG-Sequence는 동일한 검색된 문서를 사용하여 전체 시퀀스를 생성하는 반면, RAG-Token은 각 타겟 토큰에 대해 다른 문서를 선택할 수 있습니다.\n",
      "\n",
      "4. **지식 업데이트**: 비파라메트릭 메모리는 세계의 변화에 따라 모델의 지식을 업데이트하는 데 사용될 수 있으며, 이는 RAG 모델의 유연성을 높입니다.\n",
      "\n",
      "5. **구현 세부사항 및 훈련 설정**: RAG 모델은 Open-domain QA에서 15개 또는 50개의 문서를 사용하여 테스트되며, Fairseq를 통해 훈련됩니다. 훈련 과정에서 8개의 32GB NVIDIA V100 GPU를 활용하며, 코드가 HuggingFace Transformers로 포팅되어 오픈 소스로 제공됩니다.\n",
      "\n",
      "6. **인간 평가 및 데이터셋**: 사용자 인터페이스를 통해 평가자들이 주제를 조사하도록 권장하며, 다양한 데이터셋의 훈련, 개발, 테스트 인스턴스 수가 정리되어 있습니다. RAG-Sequence 모델은 44.5의 EM 점수를 기록하여 하이브리드 모델의 강력한 성능을 보여줍니다.\n",
      "\n",
      "7. **검색 기능의 문제**: 초기 실험에서 일부 작업에서 검색 구성 요소가 \"붕괴\"되어 입력에 관계없이 동일한 문서를 검색하는 경향이 나타났으며, 이는 특정 작업에서 사실적 지식의 요구가 덜 명확할 수 있음을 시사합니다.\n",
      "\n",
      "이 연구는 RAG 모델이 정보 검색과 생성 작업에서 어떻게 효과적으로 작동하는지를 보여주며, 파라메트릭 및 비파라메트릭 메모리의 결합이 모델의 성능을 향상시키는 데 기여함을 강조합니다. RAG 모델은 다양한 NLP 작업에서 강력한 성능을 달성할 수 있는 가능성을 제시합니다.\n"
     ]
    }
   ],
   "source": [
    "# 요약결과 출력\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [LOG] 순서를 매겨서 잘 요약하였음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [MY CODE] MapReduce 방법으로 논문 요약 (new version - Runnable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get llm\n",
    "llm = ChatOpenAI(temperature=0, \n",
    "                 model_name='gpt-4o-mini',\n",
    "                 api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map에 사용할 prompt template\n",
    "map_template = \"\"\"다음은 문서 중 일부 내용입니다\n",
    "{pages}\n",
    "이 문서 목록을 기반으로 주요 내용을 요약해 주세요.\n",
    "답변:\"\"\"\n",
    "\n",
    "# Map 프롬프트\n",
    "map_prompt = ChatPromptTemplate([(\"human\", map_template)])\n",
    "\n",
    "# Runnable 형식 사용\n",
    "map_chain = map_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce에 사용할 prompt template\n",
    "reduce_template = \"\"\"다음은 요약의 집합입니다:\n",
    "{doc_summaries}\n",
    "이것으로 통합된 요약을 만들어 주세요.\n",
    "답변:\"\"\"\n",
    "\n",
    "# Reduce 프롬프트\n",
    "reduce_prompt = ChatPromptTemplate([(\"human\", reduce_template)])\n",
    "\n",
    "# Runnable 형식 사용\n",
    "reduce_chain = reduce_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, TypedDict\n",
    "\n",
    "from langgraph.constants import Send\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "\n",
    "class OverallState(TypedDict):\n",
    "    # Notice here we use the operator.add\n",
    "    # This is because we want combine all the summaries we generate\n",
    "    # from individual nodes back into one list - this is essentially\n",
    "    # the \"reduce\" part\n",
    "    contents: List[str]\n",
    "    summaries: Annotated[list, operator.add]\n",
    "    final_summary: str\n",
    "\n",
    "\n",
    "# This will be the state of the node that we will \"map\" all\n",
    "# documents to in order to generate summaries\n",
    "class SummaryState(TypedDict):\n",
    "    content: str\n",
    "\n",
    "\n",
    "# Here we generate a summary, given a document\n",
    "async def generate_summary(state: SummaryState):\n",
    "    response = await map_chain.ainvoke(state[\"content\"])\n",
    "    return {\"summaries\": [response]}\n",
    "\n",
    "\n",
    "# Here we define the logic to map out over the documents\n",
    "# We will use this an edge in the graph\n",
    "def map_summaries(state: OverallState):\n",
    "    # We will return a list of `Send` objects\n",
    "    # Each `Send` object consists of the name of a node in the graph\n",
    "    # as well as the state to send to that node\n",
    "    return [\n",
    "        Send(\"generate_summary\", {\"content\": content}) for content in state[\"contents\"]\n",
    "    ]\n",
    "\n",
    "\n",
    "# Here we will generate the final summary\n",
    "async def generate_final_summary(state: OverallState):\n",
    "    response = await reduce_chain.ainvoke(state[\"summaries\"])\n",
    "    return {\"final_summary\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the graph: here we put everything together to construct our graph\n",
    "graph = StateGraph(OverallState)\n",
    "graph.add_node(\"generate_summary\", generate_summary)\n",
    "graph.add_node(\"generate_final_summary\", generate_final_summary)\n",
    "graph.add_conditional_edges(START, map_summaries, [\"generate_summary\"])\n",
    "graph.add_edge(\"generate_summary\", \"generate_final_summary\")\n",
    "graph.add_edge(\"generate_final_summary\", END)\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(app.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_final_summary']\n"
     ]
    }
   ],
   "source": [
    "rsts = []\n",
    "# split_docs 순서 대로 요약 시작\n",
    "async for step in app.astream({\"contents\": [doc.page_content for doc in split_docs]}):\n",
    "    rsts.append(step)\n",
    "    print(list(step.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 문서는 Retrieval-Augmented Generation (RAG) 모델에 대한 연구를 다루고 있으며, RAG 모델은 정보 검색과 텍스트 생성을 결합하여 지식 집약적인 자연어 처리(NLP) 작업에서 우수한 성능을 발휘하는 방법을 제안합니다. 주요 내용은 다음과 같습니다:\n",
      "\n",
      "1. **모델 구조**: RAG 모델은 두 가지 주요 구성 요소로 이루어져 있습니다. 첫째, 입력 쿼리에 대해 관련 문서를 검색하는 검색기(DPR)와 둘째, 검색된 문서와 입력을 기반으로 텍스트를 생성하는 생성기(BART)입니다. RAG-Sequence와 RAG-Token 두 가지 형식이 있으며, 각각의 방식으로 문서를 처리합니다.\n",
      "\n",
      "2. **하이브리드 메모리**: RAG는 파라메트릭 메모리(사전 훈련된 seq2seq 모델)와 비파라메트릭 메모리(밀집 벡터 인덱스)를 결합하여 외부 지식 소스에 접근할 수 있는 능력을 강화합니다. 이를 통해 모델은 지식을 효과적으로 활용하고 업데이트할 수 있습니다.\n",
      "\n",
      "3. **성능 평가**: RAG 모델은 Natural Questions, WebQuestions, TriviaQA, MSMARCO 등 다양한 공개 데이터셋에서 최첨단 성능을 달성하였으며, Jeopardy 질문 생성 및 FEVER 사실 검증 작업에서도 우수한 결과를 보였습니다. RAG는 기존의 파라메트릭 모델과 비교하여 더 사실적이고 구체적인 응답을 생성하는 경향이 있습니다.\n",
      "\n",
      "4. **훈련 및 디코딩 방법**: RAG 모델은 SGD와 Adam 옵티마이저를 사용하여 훈련되며, 검색기와 생성기를 공동으로 최적화합니다. 디코딩 방법에서는 RAG-Token과 RAG-Sequence가 서로 다른 방식으로 결과를 생성하여 성능을 극대화합니다.\n",
      "\n",
      "5. **사회적 영향 및 위험**: RAG 모델은 Wikipedia와 같은 사실 기반 지식을 활용하여 정보의 정확성을 높이는 데 기여할 수 있지만, 외부 지식 출처의 편향과 허위 정보 생성 등의 잠재적 위험도 존재합니다. 이러한 위험을 완화하기 위한 방안도 논의됩니다.\n",
      "\n",
      "이 연구는 RAG 모델이 지식 집약적인 NLP 작업에서 어떻게 효과적으로 작동하는지를 보여주며, 파라메트릭 및 비파라메트릭 메모리의 결합이 NLP 작업에 미치는 긍정적인 영향을 강조합니다. RAG 모델은 다양한 NLP 작업에서의 활용 가능성을 제시하며, 향후 연구 방향에 대한 통찰을 제공합니다.\n"
     ]
    }
   ],
   "source": [
    "# 마지막 전체 요약\n",
    "print(step['generate_final_summary']['final_summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [LOG] 속도와 요약내용 비교\n",
    "- old version보다 속도는 빨랐음 (3분 54초 vs 26초)\n",
    "- 요약 내용에 대해서는 old version이 더 자세하게 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split_docs (19) + final_summary (1)\n",
    "len(rsts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 문서 목록은 자연어 처리(NLP) 및 인공지능(AI) 분야의 다양한 연구 결과를 포함하고 있습니다. 주요 내용을 요약하면 다음과 같습니다:\n",
      "\n",
      "1. **독해 및 질문 응답**:\n",
      "   - Christopher Clark와 Matt Gardner의 연구는 다단락 독해 이해를 위한 간단하고 효과적인 방법을 제안합니다.\n",
      "   - Matthew Dunn 외의 연구는 SearchQA라는 새로운 질문 응답 데이터셋을 소개하며, 검색 엔진의 맥락을 활용합니다.\n",
      "   - Angela Fan 외의 ELI5 연구는 긴 형식의 질문 응답을 다룹니다.\n",
      "\n",
      "2. **언어 모델 및 변환기**:\n",
      "   - Jacob Devlin 외의 BERT 연구는 심층 양방향 변환기를 통한 언어 이해의 사전 훈련 방법을 제시합니다.\n",
      "   - Angela Fan 외의 연구는 KNN 기반의 복합 메모리로 변환기를 보강하는 방법을 탐구합니다.\n",
      "\n",
      "3. **대화형 AI**:\n",
      "   - Emily Dinan 외의 연구는 지식 기반 대화형 에이전트를 위한 \"위자드 오브 위키피디아\" 모델을 제안합니다.\n",
      "   - Marjan Ghazvininejad 외의 연구는 지식 기반 신경 대화 모델을 개발합니다.\n",
      "\n",
      "4. **기계 번역**:\n",
      "   - Jiatao Gu 외의 연구는 검색 엔진을 활용한 신경 기계 번역 방법을 제안합니다.\n",
      "\n",
      "5. **AI 성능 예측**:\n",
      "   - Katja Grace 외의 연구는 AI가 인간 성능을 초과할 시점을 예측하기 위한 전문가 의견을 수집합니다.\n",
      "\n",
      "이 문서들은 NLP와 AI의 최신 동향을 반영하며, 다양한 기술적 접근과 응용 사례를 통해 이 분야의 발전을 보여줍니다.\n"
     ]
    }
   ],
   "source": [
    "# 첫 splits 요약 예시\n",
    "print(rsts[0]['generate_summary']['summaries'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [LOG] 문서 및 글 참조\n",
    "\n",
    "- https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain/\n",
    "- https://teddylee777.github.io/langchain/langchain-tutorial-07/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
