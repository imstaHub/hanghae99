{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week7 Basic Homework\n",
    "\n",
    "- week4 basic에서 실행한 모델 학습을 재연 및 wandb를 사용하여 metric 관찰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import wandb\n",
    "import logging\n",
    "import datasets\n",
    "import evaluate\n",
    "import transformers\n",
    "import numpy as np\n",
    "\n",
    "from typing import Optional\n",
    "from itertools import chain\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "#device setting\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.backends.cuda.is_built():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimsta\u001b[0m (\u001b[33mimsta-hub\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/jh/workspaces/notebook/voyage/homework/wandb/run-20250205_214554-700nws2c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imsta-hub/Hanghae99/runs/700nws2c' target=\"_blank\">major-voice-8</a></strong> to <a href='https://wandb.ai/imsta-hub/Hanghae99' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imsta-hub/Hanghae99' target=\"_blank\">https://wandb.ai/imsta-hub/Hanghae99</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imsta-hub/Hanghae99/runs/700nws2c' target=\"_blank\">https://wandb.ai/imsta-hub/Hanghae99/runs/700nws2c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wandb 접속\n",
    "wandb.init(project='Hanghae99')\n",
    "wandb.run.name = 'gpt-finetuning'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [MY CODE] Arguments 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Arguments:\n",
    "    model_name_or_path: Optional[str] = field(default=None)  # HuggingFace hub에서 pre-trained 모델로 사용할 모델의 이름\n",
    "    torch_dtype: Optional[str] = field(default=None, metadata={'choices': ['auto', 'bfloat16', 'float16', 'float32']})  # 우리 모델의 precision(data type이라고 이해하시면 됩니다)\n",
    "\n",
    "    dataset_name: Optional[str] = field(default=None)  # Fine-tuning으로 사용할 huggingface hub에서의 dataset 이름\n",
    "    dataset_config_name: Optional[str] = field(default=None)  # Fine-tuning으로 사용할 huggingface hub에서의 dataset configuration\n",
    "    block_size: int = field(default=1024)  # Fine-tuning에 사용할 input text의 길이\n",
    "    num_workers: Optional[int] = field(default=None)  # Data를 업로드하거나 전처리할 때 사용할 worker 숫자\n",
    "\n",
    "\n",
    "args = Arguments(model_name_or_path=\"distilbert/distilbert-base-uncased\",\n",
    "                 torch_dtype='auto',\n",
    "                 dataset_name=\"nyu-mll/glue\",\n",
    "                 dataset_config_name=\"mnli\",\n",
    "                 num_workers=1\n",
    "                 )\n",
    "training_args = TrainingArguments(output_dir=os.path.join(os.getcwd(),'my_model'),\n",
    "                                  learning_rate=1e-4,\n",
    "                                  per_device_train_batch_size=32,\n",
    "                                  per_device_eval_batch_size=32,\n",
    "                                  num_train_epochs=5,\n",
    "                                  weight_decay=0.01,\n",
    "                                  eval_strategy=\"epoch\",\n",
    "                                  save_strategy=\"epoch\",\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  report_to = \"wandb\",\n",
    "                                  push_to_hub=False\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [MY CODE] logger 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "\n",
    "if training_args.should_log:\n",
    "    transformers.utils.logging.set_verbosity_info()  # log level을 INFO로 변경\n",
    "\n",
    "# log level: 10 DEBUG, 20 INFO, 30 WARNING, 40 ERROR, 50 CRITICAL\n",
    "log_level = training_args.get_process_log_level()\n",
    "\n",
    "# 우리가 가지고 있는 logger와 HuggingFace의 logger의 log level 설정\n",
    "logger.setLevel(log_level)\n",
    "datasets.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "\n",
    "# 기타 HuggingFace logger option들을 설정\n",
    "transformers.utils.logging.enable_default_handler() # logger 기능 활성화\n",
    "transformers.utils.logging.enable_explicit_format() # 포맷 설정: [LEVELNAME|FILENAME|LINE NUMBER] TIME >> MESSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/05/2025 21:46:08 - INFO - root - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=None,\n",
      "eval_strategy=IntervalStrategy.EPOCH,\n",
      "eval_use_gather_object=False,\n",
      "evaluation_strategy=None,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=False,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/Users/jh/workspaces/notebook/voyage/homework/my_model/runs/Feb05_21-46-05_MacBook-Pro.local,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=loss,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=5,\n",
      "optim=OptimizerNames.ADAMW_TORCH,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=/Users/jh/workspaces/notebook/voyage/homework/my_model,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=32,\n",
      "per_device_train_batch_size=32,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['wandb'],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/Users/jh/workspaces/notebook/voyage/homework/my_model,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=SaveStrategy.EPOCH,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Training arguments 확인\n",
    "logger.info(f\"Training/evaluation parameters {training_args}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [MY CODE] Dataset 및 Model 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/05/2025 21:46:15 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from /Users/jh/.cache/huggingface/datasets/nyu-mll___glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/05/2025 21:46:15 - INFO - datasets.info - Loading Dataset info from /Users/jh/.cache/huggingface/datasets/nyu-mll___glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/Users/jh/.cache/huggingface/datasets/nyu-mll___glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/05/2025 21:46:15 - INFO - datasets.builder - Found cached dataset glue (/Users/jh/.cache/huggingface/datasets/nyu-mll___glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from /Users/jh/.cache/huggingface/datasets/nyu-mll___glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/05/2025 21:46:15 - INFO - datasets.info - Loading Dataset info from /Users/jh/.cache/huggingface/datasets/nyu-mll___glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\n",
    "    args.dataset_name,\n",
    "    args.dataset_config_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:695] 2025-02-05 21:46:17,216 >> loading configuration file config.json from cache at /Users/jh/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/config.json\n",
      "[INFO|configuration_utils.py:762] 2025-02-05 21:46:17,222 >> Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert/distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.47.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:695] 2025-02-05 21:46:17,440 >> loading configuration file config.json from cache at /Users/jh/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/config.json\n",
      "[INFO|configuration_utils.py:762] 2025-02-05 21:46:17,442 >> Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert/distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.47.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2030] 2025-02-05 21:46:17,446 >> loading file vocab.txt from cache at /Users/jh/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:2030] 2025-02-05 21:46:17,447 >> loading file tokenizer.json from cache at /Users/jh/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2030] 2025-02-05 21:46:17,448 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2030] 2025-02-05 21:46:17,449 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2030] 2025-02-05 21:46:17,450 >> loading file tokenizer_config.json from cache at /Users/jh/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2030] 2025-02-05 21:46:17,451 >> loading file chat_template.jinja from cache at None\n",
      "[INFO|configuration_utils.py:695] 2025-02-05 21:46:17,454 >> loading configuration file config.json from cache at /Users/jh/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/config.json\n",
      "[INFO|configuration_utils.py:762] 2025-02-05 21:46:17,456 >> Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert/distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.47.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3953] 2025-02-05 21:46:17,511 >> loading weights file model.safetensors from cache at /Users/jh/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/model.safetensors\n",
      "[INFO|modeling_utils.py:4060] 2025-02-05 21:46:17,527 >> Since the `torch_dtype` attribute can't be found in model's config object, will use torch_dtype={torch_dtype} as derived from model's weights\n",
      "[INFO|modeling_utils.py:1641] 2025-02-05 21:46:17,527 >> Instantiating DistilBertForSequenceClassification model under default dtype torch.float32.\n",
      "[INFO|modeling_utils.py:4839] 2025-02-05 21:46:17,542 >> Some weights of the model checkpoint at distilbert/distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:4851] 2025-02-05 21:46:17,543 >> Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(args.model_name_or_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    args.model_name_or_path,\n",
    "    config=config,\n",
    "    torch_dtype=args.torch_dtype,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [MY CODE] dataset tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/jh/.cache/huggingface/datasets/nyu-mll___glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-ef6c312c050d1a78.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/05/2025 21:46:20 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /Users/jh/.cache/huggingface/datasets/nyu-mll___glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-ef6c312c050d1a78.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/jh/.cache/huggingface/datasets/nyu-mll___glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-9cb0fa7ca7edd13d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/05/2025 21:46:20 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /Users/jh/.cache/huggingface/datasets/nyu-mll___glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-9cb0fa7ca7edd13d.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/jh/.cache/huggingface/datasets/nyu-mll___glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-4ac0670ef11a03bc.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/05/2025 21:46:20 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /Users/jh/.cache/huggingface/datasets/nyu-mll___glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-4ac0670ef11a03bc.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/jh/.cache/huggingface/datasets/nyu-mll___glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-ef8de6694e303d1e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/05/2025 21:46:20 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /Users/jh/.cache/huggingface/datasets/nyu-mll___glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-ef8de6694e303d1e.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/jh/.cache/huggingface/datasets/nyu-mll___glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-274285747ecab6f4.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/05/2025 21:46:20 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /Users/jh/.cache/huggingface/datasets/nyu-mll___glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-274285747ecab6f4.arrow\n"
     ]
    }
   ],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "embedding_size = model.get_input_embeddings().weight.shape[0]\n",
    "if len(tokenizer) > embedding_size:\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "column_names = list(raw_datasets[\"train\"].features)\n",
    "text_column_name1 = 'premise'\n",
    "text_column_name2 = 'hypothesis'\n",
    "\n",
    "def tokenize_function(row):\n",
    "    output = tokenizer(row[text_column_name1],row[text_column_name2])\n",
    "    output['labels'] = row['label']\n",
    "    return output\n",
    "\n",
    "with training_args.main_process_first(desc=\"dataset map tokenization\"):\n",
    "    tokenized_datasets = raw_datasets.map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        num_proc=args.num_workers,\n",
    "        remove_columns=column_names\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 17158, 2135, 6949, 8301, 25057, 2038, 2048, 3937, 9646, 1011, 4031, 1998, 10505, 1012, 102, 4031, 1998, 10505, 2024, 2054, 2191, 6949, 8301, 25057, 2147, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 17158, 2135, 6949, 8301, 25057, 2038, 20...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 2017, 2113, 2076, 1996, 2161, 1998, 1045...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[101, 2028, 1997, 2256, 2193, 2097, 4287, 2041...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[101, 2129, 2079, 2017, 2113, 1029, 2035, 2023...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[101, 3398, 1045, 2425, 2017, 2054, 2295, 2065...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_ids  \\\n",
       "0  [101, 17158, 2135, 6949, 8301, 25057, 2038, 20...   \n",
       "1  [101, 2017, 2113, 2076, 1996, 2161, 1998, 1045...   \n",
       "2  [101, 2028, 1997, 2256, 2193, 2097, 4287, 2041...   \n",
       "3  [101, 2129, 2079, 2017, 2113, 1029, 2035, 2023...   \n",
       "4  [101, 3398, 1045, 2425, 2017, 2054, 2295, 2065...   \n",
       "\n",
       "                                      attention_mask  labels  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       1  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0  \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokenized_datasets['train'][0])\n",
    "tokenized_datasets['train'].data.to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 392702\n",
       "    })\n",
       "    validation_matched: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 9815\n",
       "    })\n",
       "    validation_mismatched: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 9832\n",
       "    })\n",
       "    test_matched: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 9796\n",
       "    })\n",
       "    test_mismatched: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 9847\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [MY CODE] 모델 학습\n",
    "- metric으로 accuracy 추가\n",
    "- 로컬 실행하기에는 데이터셋이 너무 커서 train의 5%만 사용하여 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching indices mapping at /Users/jh/.cache/huggingface/datasets/nyu-mll___glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-9ea1ff0b47ea8161.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/05/2025 21:46:30 - INFO - datasets.arrow_dataset - Caching indices mapping at /Users/jh/.cache/huggingface/datasets/nyu-mll___glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-9ea1ff0b47ea8161.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching indices mapping at /Users/jh/.cache/huggingface/datasets/nyu-mll___glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-ceb8c3069f319662.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/05/2025 21:46:30 - INFO - datasets.arrow_dataset - Caching indices mapping at /Users/jh/.cache/huggingface/datasets/nyu-mll___glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-ceb8c3069f319662.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2362] 2025-02-05 21:46:30,874 >> ***** Running training *****\n",
      "[INFO|trainer.py:2363] 2025-02-05 21:46:30,874 >>   Num examples = 19,635\n",
      "[INFO|trainer.py:2364] 2025-02-05 21:46:30,875 >>   Num Epochs = 5\n",
      "[INFO|trainer.py:2365] 2025-02-05 21:46:30,875 >>   Instantaneous batch size per device = 32\n",
      "[INFO|trainer.py:2368] 2025-02-05 21:46:30,876 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:2369] 2025-02-05 21:46:30,876 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:2370] 2025-02-05 21:46:30,876 >>   Total optimization steps = 3,070\n",
      "[INFO|trainer.py:2371] 2025-02-05 21:46:30,877 >>   Number of trainable parameters = 66,955,010\n",
      "[INFO|integration_utils.py:811] 2025-02-05 21:46:30,878 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79dc6693819543509572f832b4424109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3070 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.376, 'grad_norm': 2.679630994796753, 'learning_rate': 8.371335504885994e-05, 'epoch': 0.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:4203] 2025-02-05 21:51:05,222 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4205] 2025-02-05 21:51:05,223 >>   Num examples = 9815\n",
      "[INFO|trainer.py:4208] 2025-02-05 21:51:05,224 >>   Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca5230d5f4304d1ebcbe39a5ff5c67f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3887] 2025-02-05 21:52:05,571 >> Saving model checkpoint to /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-614\n",
      "[INFO|configuration_utils.py:419] 2025-02-05 21:52:05,573 >> Configuration saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-614/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3100927174091339, 'eval_accuracy': 0.5331635252165053, 'eval_runtime': 60.3476, 'eval_samples_per_second': 162.641, 'eval_steps_per_second': 5.087, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:3042] 2025-02-05 21:52:05,843 >> Model weights saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-614/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2485] 2025-02-05 21:52:05,844 >> tokenizer config file saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-614/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2494] 2025-02-05 21:52:05,845 >> Special tokens file saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-614/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2447, 'grad_norm': 6.208848476409912, 'learning_rate': 6.742671009771987e-05, 'epoch': 1.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:4203] 2025-02-05 21:56:47,780 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4205] 2025-02-05 21:56:47,781 >>   Num examples = 9815\n",
      "[INFO|trainer.py:4208] 2025-02-05 21:56:47,781 >>   Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27cdcf08a49b4c70b09d83d18d6433fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3887] 2025-02-05 21:57:42,879 >> Saving model checkpoint to /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-1228\n",
      "[INFO|configuration_utils.py:419] 2025-02-05 21:57:42,882 >> Configuration saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-1228/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.345465749502182, 'eval_accuracy': 0.5203260315843097, 'eval_runtime': 55.0983, 'eval_samples_per_second': 178.136, 'eval_steps_per_second': 5.572, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:3042] 2025-02-05 21:57:43,108 >> Model weights saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-1228/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2485] 2025-02-05 21:57:43,110 >> tokenizer config file saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-1228/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2494] 2025-02-05 21:57:43,111 >> Special tokens file saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-1228/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1602, 'grad_norm': 17.073707580566406, 'learning_rate': 5.114006514657981e-05, 'epoch': 2.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:4203] 2025-02-05 22:02:13,045 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4205] 2025-02-05 22:02:13,046 >>   Num examples = 9815\n",
      "[INFO|trainer.py:4208] 2025-02-05 22:02:13,046 >>   Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b374fa4b36584015aa5f5019ec900b67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3887] 2025-02-05 22:03:07,354 >> Saving model checkpoint to /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-1842\n",
      "[INFO|configuration_utils.py:419] 2025-02-05 22:03:07,356 >> Configuration saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-1842/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4236220717430115, 'eval_accuracy': 0.53428425878757, 'eval_runtime': 54.3076, 'eval_samples_per_second': 180.73, 'eval_steps_per_second': 5.653, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:3042] 2025-02-05 22:03:07,552 >> Model weights saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-1842/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2485] 2025-02-05 22:03:07,554 >> tokenizer config file saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-1842/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2494] 2025-02-05 22:03:07,555 >> Special tokens file saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-1842/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0883, 'grad_norm': 4.680767059326172, 'learning_rate': 3.485342019543974e-05, 'epoch': 3.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:4203] 2025-02-05 22:07:33,689 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4205] 2025-02-05 22:07:33,690 >>   Num examples = 9815\n",
      "[INFO|trainer.py:4208] 2025-02-05 22:07:33,691 >>   Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bc4a0d5c8f4ffb9a3edc844b28dd20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3887] 2025-02-05 22:08:27,855 >> Saving model checkpoint to /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-2456\n",
      "[INFO|configuration_utils.py:419] 2025-02-05 22:08:27,858 >> Configuration saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-2456/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.602651059627533, 'eval_accuracy': 0.5360163015792155, 'eval_runtime': 54.1648, 'eval_samples_per_second': 181.206, 'eval_steps_per_second': 5.668, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:3042] 2025-02-05 22:08:28,061 >> Model weights saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-2456/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2485] 2025-02-05 22:08:28,062 >> tokenizer config file saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-2456/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2494] 2025-02-05 22:08:28,063 >> Special tokens file saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-2456/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0475, 'grad_norm': 0.02795957215130329, 'learning_rate': 1.8566775244299675e-05, 'epoch': 4.07}\n",
      "{'loss': 0.0218, 'grad_norm': 0.016305916011333466, 'learning_rate': 2.280130293159609e-06, 'epoch': 4.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3887] 2025-02-05 22:12:56,639 >> Saving model checkpoint to /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-3070\n",
      "[INFO|configuration_utils.py:419] 2025-02-05 22:12:56,641 >> Configuration saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-3070/config.json\n",
      "[INFO|modeling_utils.py:3042] 2025-02-05 22:12:56,830 >> Model weights saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-3070/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2485] 2025-02-05 22:12:56,831 >> tokenizer config file saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-3070/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2494] 2025-02-05 22:12:56,832 >> Special tokens file saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-3070/special_tokens_map.json\n",
      "[INFO|trainer.py:4203] 2025-02-05 22:12:57,750 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4205] 2025-02-05 22:12:57,751 >>   Num examples = 9815\n",
      "[INFO|trainer.py:4208] 2025-02-05 22:12:57,751 >>   Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe5cce53b844916a6704a4c9ec6653b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3887] 2025-02-05 22:13:52,093 >> Saving model checkpoint to /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-3070\n",
      "[INFO|configuration_utils.py:419] 2025-02-05 22:13:52,095 >> Configuration saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-3070/config.json\n",
      "[INFO|modeling_utils.py:3042] 2025-02-05 22:13:52,264 >> Model weights saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-3070/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2485] 2025-02-05 22:13:52,266 >> tokenizer config file saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-3070/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2494] 2025-02-05 22:13:52,266 >> Special tokens file saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-3070/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7396935820579529, 'eval_accuracy': 0.5350993377483444, 'eval_runtime': 54.3419, 'eval_samples_per_second': 180.616, 'eval_steps_per_second': 5.649, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2636] 2025-02-05 22:13:52,939 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2874] 2025-02-05 22:13:52,940 >> Loading best model from /Users/jh/workspaces/notebook/voyage/homework/my_model/checkpoint-614 (score: 0.3100927174091339).\n",
      "[INFO|trainer.py:3887] 2025-02-05 22:13:53,377 >> Saving model checkpoint to /Users/jh/workspaces/notebook/voyage/homework/my_model\n",
      "[INFO|configuration_utils.py:419] 2025-02-05 22:13:53,379 >> Configuration saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/config.json\n",
      "[INFO|modeling_utils.py:3042] 2025-02-05 22:13:53,521 >> Model weights saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2485] 2025-02-05 22:13:53,522 >> tokenizer config file saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2494] 2025-02-05 22:13:53,523 >> Special tokens file saved in /Users/jh/workspaces/notebook/voyage/homework/my_model/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1642.4867, 'train_samples_per_second': 59.772, 'train_steps_per_second': 1.869, 'train_loss': 0.1533355787833273, 'epoch': 5.0}\n",
      "***** train metrics *****\n",
      "  epoch                    =        5.0\n",
      "  total_flos               =  2162261GF\n",
      "  train_loss               =     0.1533\n",
      "  train_runtime            = 0:27:22.48\n",
      "  train_samples_per_second =     59.772\n",
      "  train_steps_per_second   =      1.869\n"
     ]
    }
   ],
   "source": [
    "# dataset이 너무 커서 5%만 사용\n",
    "splits = tokenized_datasets['train'].train_test_split(test_size=0.95, train_size=0.05)\n",
    "train_dataset = splits['train']\n",
    "validation_dataset = tokenized_datasets['validation_matched']\n",
    "\n",
    "# 토큰화가 진행되었기 때문에 padding만 해줄 collator 선택\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "checkpoint = None\n",
    "last_checkpoint = get_last_checkpoint(training_args.output_dir)  # 만약 output_dir에 checkpoint가 남아있으면 이를 사용하고, 없으면 None이 return됩니다.\n",
    "if training_args.resume_from_checkpoint is not None:  # output_dir이 아닌 다른 위치에서의 checkpoint를 resume_from_checkpoint로 지정할 수 있습니다.\n",
    "    checkpoint = training_args.resume_from_checkpoint\n",
    "else:  # 아니면 last_checkpoint로 checkpoint를 지정합니다.\n",
    "    checkpoint = last_checkpoint\n",
    "\n",
    "train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
    "\n",
    "trainer.save_model()\n",
    "\n",
    "metrics = train_result.metrics\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▇▁▇██</td></tr><tr><td>eval/loss</td><td>▁▂▃▆█</td></tr><tr><td>eval/runtime</td><td>█▂▁▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▇███</td></tr><tr><td>eval/steps_per_second</td><td>▁▇███</td></tr><tr><td>train/epoch</td><td>▁▁▂▃▄▅▅▆▆███</td></tr><tr><td>train/global_step</td><td>▁▁▂▃▄▅▅▆▆███</td></tr><tr><td>train/grad_norm</td><td>▂▄█▃▁▁</td></tr><tr><td>train/learning_rate</td><td>█▇▅▄▂▁</td></tr><tr><td>train/loss</td><td>█▅▄▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.5351</td></tr><tr><td>eval/loss</td><td>0.73969</td></tr><tr><td>eval/runtime</td><td>54.3419</td></tr><tr><td>eval/samples_per_second</td><td>180.616</td></tr><tr><td>eval/steps_per_second</td><td>5.649</td></tr><tr><td>total_flos</td><td>2321710301850036.0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>3070</td></tr><tr><td>train/grad_norm</td><td>0.01631</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0218</td></tr><tr><td>train_loss</td><td>0.15334</td></tr><tr><td>train_runtime</td><td>1642.4867</td></tr><tr><td>train_samples_per_second</td><td>59.772</td></tr><tr><td>train_steps_per_second</td><td>1.869</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gpt-finetuning</strong> at: <a href='https://wandb.ai/imsta-hub/Hanghae99/runs/700nws2c' target=\"_blank\">https://wandb.ai/imsta-hub/Hanghae99/runs/700nws2c</a><br> View project at: <a href='https://wandb.ai/imsta-hub/Hanghae99' target=\"_blank\">https://wandb.ai/imsta-hub/Hanghae99</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250205_214554-700nws2c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
